{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extractive Summarisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from nltk import word_tokenize, sent_tokenize, FreqDist,pos_tag\n",
    "from nltk.corpus import stopwords, wordnet as wn\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from operator import itemgetter\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convergence threshold is the maximum error in score convergence of TextRank\n",
    "CONVERGENCE_THRESHOLD = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set of all nouns\n",
    "NOUNS = {x.name().split('.', 1)[0] for x in wn.all_synsets('n')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Document():\n",
    "    '''\n",
    "    The master class for our Document Summerization module.\n",
    "    Incorporates all features related to Document\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, document):\n",
    "        self.document = document\n",
    "        #self.sents = sent_tokenize(self.document)\n",
    "        self.sents = self.document.split('\\n')\n",
    "        self.word_freq = FreqDist(clean(self.document))\n",
    "        self.graph = None\n",
    "        self.params = { 'thresh': 0.0 }\n",
    "                \n",
    "    def __str__(self):\n",
    "        return self.document\n",
    "    \n",
    "    \n",
    "    def statistical_sim(self, sent1, sent2):\n",
    "        '''\n",
    "        Statistical similarity between sentences\n",
    "        based on the cosine method\n",
    "        Returns: float (the cosine similarity b/w sent1 and sent2)\n",
    "        '''\n",
    "        sent_token1 = Counter(sent1)\n",
    "        sent_token2 = Counter(sent2)\n",
    "        \n",
    "        intxn = set(sent_token1) & set(sent_token2)\n",
    "        numerator = sum([sent_token1[x] * sent_token2[x] for x in intxn])\n",
    "        \n",
    "        mod1 = sum([sent_token1[x]**2 for x in sent_token1.keys()])\n",
    "        mod2 = sum([sent_token2[x]**2 for x in sent_token2.keys()])\n",
    "        denominator = sqrt(mod1)*sqrt(mod2)\n",
    "        \n",
    "        if not denominator:\n",
    "            return 0.0\n",
    "\n",
    "        return float(numerator)/denominator\n",
    "    \n",
    "    \n",
    "    def semantic_sim(self, sent1, sent2):\n",
    "        '''\n",
    "        A semantic similarity score between two sentences\n",
    "        based on WordNet\n",
    "        Returns: float (the semantic similarity measure)\n",
    "        '''\n",
    "        score = 0\n",
    "        sent1 = [word for word in sent1 if word in NOUNS]\n",
    "        sent2 = [word for word in sent2 if word in NOUNS]\n",
    "        for t1 in sent1:\n",
    "            for t2 in sent2:\n",
    "                score += semantic_score(t1,t2)\n",
    "        try:\n",
    "            return score/(len(sent1 + sent2))  \n",
    "        except:\n",
    "            return 10000\n",
    "    \n",
    "    \n",
    "    def construct_graph(self):\n",
    "        '''\n",
    "        Constructs the word similarity graph\n",
    "        '''\n",
    "        connected = []\n",
    "        for pair in combinations(self.sents, 2):\n",
    "            cpair = clean(pair[0]), clean(pair[1])\n",
    "            weight = self.statistical_sim(*cpair) + \\\n",
    "                     self.semantic_sim(*cpair)\n",
    "            connected.append((pair[0], pair[1], weight))\n",
    "        self.graph = draw_graph(connected, self.params['thresh'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def clean(sent):\n",
    "    '''\n",
    "    A utility function that returns a a list of words in a sentence\n",
    "    after cleaning it. Gets rid off uppper-case, punctuations, \n",
    "    stop words, etc.\n",
    "    Returns: list (a list of cleaned words in sentence)\n",
    "    '''\n",
    "    words =  sent.lower() \n",
    "    words = re.findall(r'\\w+', words,flags = re.UNICODE | re.LOCALE) \n",
    "    imp_words = filter(lambda x: x not in stopwords.words('english'), words)\n",
    "    return imp_words\n",
    "        \n",
    "def semantic_score(word1, word2):\n",
    "    '''\n",
    "    Semantic score between two words based on WordNet\n",
    "    Returns: float (the semantic score between word1 and word2)\n",
    "    '''\n",
    "    try:\n",
    "        w1 = wn.synset('%s.n.01'%(word1))\n",
    "        w2 = wn.synset('%s.n.01'%(word2))\n",
    "        return wn.path_similarity(w1,w2,simulate_root = False)\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "def draw_graph(connected, thresh):\n",
    "    '''\n",
    "    Draws graph as per weights and puts edges if \n",
    "    weight exceed the given thresh\n",
    "    Returns: networkx Graph (nodes are sentences and edges\n",
    "             are statistical and semantic relationships)\n",
    "    '''\n",
    "    nodes = set([n1 for n1, n2, n3 in connected] + \\\n",
    "                [n2 for n1, n2, n3 in connected])\n",
    "    G=nx.Graph()\n",
    "    for node in nodes:\n",
    "        G.add_node(node)\n",
    "    for edge in connected:\n",
    "        if edge[2] > thresh:\n",
    "            G.add_edge(edge[0], edge[1],weight = edge[2])\n",
    "    #plt.figure(figsize=(8,8))\n",
    "    #pos = nx.spring_layout(G)\n",
    "    #nx.draw(G,node_color='#A0CBE2', edge_color='orange',width=1,with_labels=False)\n",
    "    #plt.show()\n",
    "    return G\n",
    "    \n",
    "def textrank_weighted(graph, initial_value=None, damping=0.85):\n",
    "    '''\n",
    "    Calculates PageRank for an undirected graph\n",
    "    Returns: A list of tuples representing sentences and respective\n",
    "    scores in descending order\n",
    "    '''\n",
    "    if initial_value == None:\n",
    "        initial_value = 1.0 / len(graph.nodes())\n",
    "    scores = dict.fromkeys(graph.nodes(), initial_value)\n",
    "\n",
    "    iteration_quantity = 0\n",
    "    for iteration_number in xrange(100):\n",
    "        iteration_quantity += 1\n",
    "        convergence_achieved = 0\n",
    "        for i in graph.nodes():\n",
    "            rank = 1 - damping\n",
    "            for j in graph.neighbors(i):\n",
    "                neighbors_sum = sum([graph.get_edge_data(j, k)['weight'] for k in graph.neighbors(j)])\n",
    "                rank += damping * scores[j] * graph.get_edge_data(j, i)['weight'] / neighbors_sum\n",
    "\n",
    "            if abs(scores[i] - rank) <= CONVERGENCE_THRESHOLD:\n",
    "                convergence_achieved += 1\n",
    "\n",
    "            scores[i] = rank\n",
    "\n",
    "        if convergence_achieved == len(graph.nodes()):\n",
    "            break\n",
    "    return sorted(scores.items(), key=itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter OAuth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import json\n",
    "from tweepy import Stream\n",
    "from tweepy.streaming import StreamListener\n",
    "import re\n",
    "import csv as csv\n",
    "from time import strftime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tweet_cleaner(tweet):\n",
    "    ''' Cleans the tweet by removing hyperlinks\n",
    "        and other unnecessary strings\n",
    "    '''\n",
    "    return ' '.join(re.sub(\"(RT @[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|@[A-Za-z0-9]+\",\" \",tweet).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_id(tweets,tag,tweet):\n",
    "    ''' Finds a tweet corresponding to\n",
    "        a given id. The id is obtained\n",
    "        while extracting the tweets '''\n",
    "    for t in tweets[tag]:\n",
    "        if tweet == (t[0]):\n",
    "            return t[1]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_trends(trend):\n",
    "    ''' Returns a list of top 50 trending\n",
    "        hashtags from US region '''\n",
    "    return [(i['name']) for i in trend[0]['trends']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_tweets(hashtags = [],nb_tweets = 10):\n",
    "    ''' Get nb_tweets from the list hashtags.\n",
    "        The tweets are returned as a dictionary\n",
    "        of list where each list corresponds to\n",
    "        a list of tweets of value hashtag '''\n",
    "    tweets = {}\n",
    "    for tag in hashtags[0:10]:\n",
    "        Tweets = tweepy.Cursor(api.search, q=tag).items(10)\n",
    "        text = [(tweet_cleaner((tweet.text).encode('ascii','ignore')) + '.',tweet.id) for tweet in Tweets]\n",
    "        tweets[tag] = text\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_top_tweets(tweets = {},top = 3):\n",
    "    ''' Takes in a dictionary of lists of tweets.\n",
    "        Applies extractive summarisation over\n",
    "        each list of tweets and finds the top \n",
    "        tweets. The top tweets are returned as\n",
    "        a dictionary of lists. '''\n",
    "    extract_tweets = {}\n",
    "    for tag in tweets:\n",
    "        temp = [tweet[0] for tweet in tweets[tag]]\n",
    "        string = '\\n'.join(temp)\n",
    "        a = Document(string)\n",
    "        a.construct_graph()\n",
    "        x = textrank_weighted(a.graph)\n",
    "        extract_tweets[tag] = [(i[0],find_id(tweets,tag,i[0])) for i in x[:top]]\n",
    "    return extract_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_csv(extract = {},final = {}):\n",
    "    filename = strftime(\"%m-%d-%Y.csv\")\n",
    "    print \"Saving the data to filename: \"+str(filename)\n",
    "    with open(filename,'wb') as fp:\n",
    "        p = csv.writer(fp)\n",
    "        p.writerow(['hashtag','tweets','main tweet'])\n",
    "        for tag in extract:\n",
    "            p.writerow([tag,new_extract[tag],final[tag]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_pickel(filename):\n",
    "    ''' Converts the csv file generated above to\n",
    "        the pickel format. \n",
    "        Returns None '''\n",
    "    filename = strftime(\"%m-%d-%Y\")\n",
    "    news = []\n",
    "    headlines = []\n",
    "    with open(filename+\".csv\",\"rb\") as fp:\n",
    "            reader = csv.DictReader(fp)\n",
    "            for line in reader:\n",
    "                text = ''\n",
    "                l = line['tweets'][1:-1].split(',')\n",
    "                for i in range(len(l)):\n",
    "                    l[i] = l[i].strip()\n",
    "                    l[i] = l[i].strip('()\\'')\n",
    "                for i in range(0,len(l),2):\n",
    "                    text+=l[i]\n",
    "                news.append(text)\n",
    "                l = line['main tweet'][1:-1].split(',')\n",
    "                for i in range(len(l)):\n",
    "                    l[i] = l[i].strip()\n",
    "                    l[i] = l[i].strip('()\\'')\n",
    "                headlines.append(l[0])\n",
    "    print \"Saving to the pickel file named: \"+str(filename)+\".pkl\"\n",
    "    pickle.dump((headlines,news),open(filename+\".pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display(tweets = {}):\n",
    "    ''' Utility function to display the \n",
    "        tweets present in a dictionary\n",
    "        of list tweets '''\n",
    "    for tag in tweets:\n",
    "        print tag\n",
    "        print '----------------------------------------------------------'\n",
    "        for tweet in tweets[tag]:\n",
    "            print tweet\n",
    "        print '==========================================================='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Najeeb Khan Credentials\n",
    "consumer_key = '3cFJ5hLMswDJOwXfaJGS4eNyS'\n",
    "consumer_secret = 'GRn1itnKbrCdAvHhbpjFgzWXMHePNuhDYz5scjnyhD8fC3Bnqg'\n",
    "access_token = '277893116-tcAWnc62SVdSBLUIqF5R5h92qm2Y0epfQUQJNa4l'\n",
    "access_secret = 'S47f26iaI7L0Z5AyT2NQqtsmitrMn70nZG2H5n5dyqM4C'\n",
    "\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "api = tweepy.API(auth)\n",
    "trend = api.trends_place(23424977)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hashtags = get_trends(trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets = get_tweets(hashtags,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#growingupthick\n",
      "----------------------------------------------------------\n",
      "('growingupthick when you sleep over a family members house amp no one can let you borrow jeans cause your considered fat.', 749190903546413056)\n",
      "('growingupthick when all your friends are skinny but you re there like a fat potato.', 749190901415587840)\n",
      "('growingupthick when you re cold putting you hands between your thighs because it s warm af.', 749190899335213056)\n",
      "('growingupthick not being able to wear shorts cause it be so hot you get a rash between your thighs from rubbing together so.', 749190899264028672)\n",
      "('growingupthick when your thigh coming out your ripped jeans.', 749190899192573952)\n",
      "('growingupthick not being able to wear shorts cause it be so hot you get a rash between your thighs from rubbing together so.', 749190895929405440)\n",
      "('chaan growingupthick getting thigh rashes burns when wearing shorts dresses etc bc your thighs rub together ALL THE TIME.', 749190893056368640)\n",
      "('growingupthick when you have to walk pass a group of guys.', 749190889596153856)\n",
      "('growingupthick always having to squat down in your jeans before leaving to see how tight they ll be when you sit.', 749190885812805632)\n",
      "('L t c super bien pour les autres mais pour toi c l horreur pcq t as pas envie de te mettre en short ou en maillot de bain.', 749190881564061696)\n",
      "===========================================================\n",
      "Joe Johnson\n",
      "----------------------------------------------------------\n",
      "('Joe Johnson is heading to the Jazz on a 2 year 22 million deal.', 749190926808059904)\n",
      "('Why the HELL would Joe Johnson sign with the Jazz of all people And for THAT cheap.', 749190922798297088)\n",
      "('Joe Johnson nuevo jugador de Utah Jazz firma por 2 aos y 22M.', 749190831802818560)\n",
      "('SEVEN TIME ALL STAR JOE JOHNSON.', 749190801067040772)\n",
      "('RT RLoading Joe Johnson and Utah is the weirdest combo.', 749190793949159425)\n",
      "('well cant say there havent been quite a few surprises in free agency this year never wouldve expected joe johnson to go to the jazz.', 749190792149929984)\n",
      "('Joe Johnson to the Jazz makes them look more like a playoff team than ever before.', 749190729860276224)\n",
      "('Joe Johnson needs to retire.', 749190726588723200)\n",
      "('According to our daldridgetnt Joe Johnson has agreed to a 2 year 22M deal with the Utah Jazz.', 749190686767886336)\n",
      "('Joe Johnson is heading to the Jazz on a 2 year 22 million deal.', 749190672356413440)\n",
      "===========================================================\n",
      "Germany vs Italy\n",
      "----------------------------------------------------------\n",
      "('GER vs ITA today Who s your winner rosietudba11 has everything you need to know.', 749191018101309440)\n",
      "('PLAYER Michael Ballack vs Daniele De Rossi RT amp Follow when voted EURO2016 DeRossi GER ITA Germany Italy.', 749191001684705280)\n",
      "('ashywaju 11930 We will air Germany vs Italy on today by 8pm on SS SELECT 30.', 749190985557639168)\n",
      "('This tag can be defined as BBC defence vs German mid fielders Hoping Germany to make a win today Go Germany go Italy or Germany.', 749190980302041089)\n",
      "('MiguelDelaney previews tonights Germany vs Italy match GERITA.', 749190979442409472)\n",
      "('Betfred betting specials for Euro 2016 continue tonight with Germany vs Italy Details.', 749190939948744705)\n",
      "('Betfred betting specials for Euro 2016 continue tonight with Germany vs Italy Details.', 749190939718127616)\n",
      "('facto Euro 2016 Germany vs Italy preview Will the Germans take revenge Daily News amp Analysis.', 749190934114496512)\n",
      "('Watch Euro2016 live at Goodge street Tonight its Germany vs Italy P S cocktails are 2for1 before 7pm.', 749190915772784641)\n",
      "('EURO16onSonyLIV So to whom u are going to cheer in today s Italy Vs Germany Take part in Poll at SonyLIV.', 749190910479478784)\n",
      "===========================================================\n",
      "All 20\n",
      "----------------------------------------------------------\n",
      "('Linda Burney becomes first Indigenous woman to serve in the House of Representatives.', 749190956084240384)\n",
      "('All 20 killed in DhakaAttack were foreigners They were all hacked to death not shot Please spare me any politically cor.', 749190952649125888)\n",
      "('Age 7 I want to be a doctor Age 16 Mum look All A s Age 20 Medicine is hard Age 35 Make some noise for DJ Musa.', 749190945380372480)\n",
      "('Age 7 I want to be a doctor Age 16 Mum look All A s Age 20 Medicine is hard Age 35 Make some noise for DJ Musa.', 749190936689868800)\n",
      "('Age 7 I want to be a doctor Age 16 Mum look All A s Age 20 Medicine is hard Age 35 Make some noise for DJ Musa.', 749190935251132416)\n",
      "('Breaking All 20 hostages killed during Bangladesh cafe siege were foreign army says.', 749190926715719680)\n",
      "('Age 7 I want to be a doctor Age 16 Mum look All A s Age 20 Medicine is hard Age 35 Make some noise for DJ Musa.', 749190921720360960)\n",
      "('Age 7 I want to be a doctor Age 16 Mum look All A s Age 20 Medicine is hard Age 35 Make some noise for DJ Musa.', 749190916708106240)\n",
      "('20 I M A MORNING PERSON PPL I m not an anything person Y do u feel the need to wake people up to do morning ppl t.', 749190913335955456)\n",
      "('How To Get Rich The Trump Method All Credit Cards Accepted.', 749190898605580289)\n",
      "===========================================================\n",
      "#ausvotes\n",
      "----------------------------------------------------------\n",
      "('JBish What do you do if a party uses monstrous lies to get elected Like Abbott We ausvotes them out AUSpol.', 749190935280361472)\n",
      "('greensjason may not win Higgins but turning a blue ribbon LiberalAus seat into a marginal seat will be a huge ach.', 749190934353498112)\n",
      "('Neither myself nor GregJennett apparently realised how tall MathiasCormann is ausvotes.', 749190933954981888)\n",
      "('The great State of Western Australia is always critical MathiasCormann on the role WA will play now that the race is close ausvotes.', 749190933804048386)\n",
      "('Nothing splitting alexbhathal and Feeney4Batman in Batman with preferences playing a huge part in it ausvotes.', 749190933476880384)\n",
      "('Nothing splitting alexbhathal and Feeney4Batman in Batman with preferences playing a huge part in it ausvotes.', 749190933455839232)\n",
      "('A most significant moment in Australian history all 50 000 years of it LindaBurneyMP ausvotes LukeLPearson.', 749190933422362624)\n",
      "('Yes it is as we thought folks looks like LNP will again blame ALP if they lose the election ROFLMAO True to form auspol ausvotes.', 749190933195862016)\n",
      "('Does anyone know who Alan Jones bed wetter Lib friend on Channel 7 election coverage just now What a fight ausvotes auspol.', 749190932843552770)\n",
      "('More cheers and applause as ABC predicts win for Labor s Linda Burney in Barton first female indigenous MP in lower hous.', 749190932633825281)\n",
      "===========================================================\n",
      "#lastrelationshiptaughtme\n",
      "----------------------------------------------------------\n",
      "('What goes around comes around lastrelationshiptaughtme.', 749190951076323328)\n",
      "('LastRelationshipTaughtMe being faithful is just not enough.', 749190947078934528)\n",
      "('lastrelationshiptaughtme that loving someone too much will fuck you up.', 749190937532698625)\n",
      "('lastrelationshiptaughtme to walk away when you re no longer happy.', 749190917194518531)\n",
      "('Only ever had one didn t rush into it and was very careful about choosing my now fiancee Loyalty is important lastrelationshiptaughtme.', 749190872831500288)\n",
      "('51 LastRelationshipTaughtMe to not give my all to a mf thats not giving their all.', 749190870784552960)\n",
      "('lastrelationshiptaughtme that even the most perfect person can be so messed up.', 749190870155407360)\n",
      "('lastrelationshiptaughtme being accused of unfaithfulness is only being brought up to cover up what they really doing.', 749190859426455552)\n",
      "('ish Itweet LastRelationshipTaughtMe never beg for someone to stay in your life if they want to leave let them leave.', 749190849125183489)\n",
      "('51 LastRelationshipTaughtMe you cant make someone be all about you and settle down Especially if thats not what they want.', 749190838584913920)\n",
      "===========================================================\n",
      "Rihanna and Drake\n",
      "----------------------------------------------------------\n",
      "('Drake and Rihanna are officially dating.', 749191021406281728)\n",
      "('Drake and Rihanna are officially dating.', 749191019967737856)\n",
      "('Rapper Drake and Rihanna together makes sense.', 749191012430540800)\n",
      "('Forgot but it was about Drake s song with Rihanna and him trying to get her and stuff.', 749191012262768640)\n",
      "('Rihanna amp Drake OFFICIALLY together Read more here Rihanna Drake ANTIWorldTour.', 749191010727714816)\n",
      "('Drake and Rihanna are officially dating.', 749191005891547136)\n",
      "('Rihanna and Drake are an official item and it is just TOO GOOD.', 749191005467971584)\n",
      "('drake and rihanna are officially dating my life is complete.', 749191002276007937)\n",
      "('Drake and Rihanna are officially dating.', 749191002087301120)\n",
      "('Rihanna and Drake are an official item and it is just TOO GOOD.', 749191001525264384)\n",
      "===========================================================\n",
      "Melvindale\n",
      "----------------------------------------------------------\n",
      "('Photo of what appears to be the car that sparked the the gas line explosion in Melvindale https.', 749190974707003392)\n",
      "('BreakingNews Gas line explodes in Melvindale WDIV Detroit WDIV Det BuyFB.', 749190865327824896)\n",
      "('Much love to those in Melvindale hoping everybody was safe.', 749190725829550080)\n",
      "('BREAKING Large gas line explosion in Melvindale homes evacuated Prayers up Details https.', 749190689930481664)\n",
      "('People talking about the heard the explosion near Melvindale damn that sucks hope everyone is safe.', 749190654924849152)\n",
      "('scollins72497 were less 15 miles from this fire and its in Melvindale.', 749190608556793856)\n",
      "('PHOTO new daylight video of Melvindale explosion scene local4.', 749190515678208000)\n",
      "('Melvindale Police Waiting for DTE evaluation before they are cleared to return melvindalefire.', 749190444576374784)\n",
      "('We re right near the burned out car Here s a look at the scene Crews now taking pictures of situation melvindale ht.', 749190444446277632)\n",
      "('BREAKING Large gas line explosion in Melvindale homes evacuated Prayers up Details https.', 749190430403637254)\n",
      "===========================================================\n",
      "#IAmStillAwakeBecause\n",
      "----------------------------------------------------------\n",
      "('IAmStillAwakeBecause I couldn t sleep And the sad part is I gotta be to work in like three hours.', 749190891143778305)\n",
      "('IAmStillAwakeBecause cuz da cat piss was powerful.', 749190890699186177)\n",
      "('IAmStillAwakeBecause Barbie Life in the Dreamhouse isn t gonna watch itself.', 749190868968411136)\n",
      "('IAmStillAwakeBecause The Australian Federal Election is on and it s looking to be coloured Brexit Watch us world.', 749190848517009409)\n",
      "('IAmStillAwakeBecause I don t sleep I just retreat to my racist cocoon which doubles as a tanning bed BAD.', 749190842762616832)\n",
      "('IAmStillAwakeBecause I m working cna NightShift.', 749190834797543424)\n",
      "('IAmStillAwakeBecause ugh i cant sleep i can never sLEep.', 749190828078174209)\n",
      "('IAmStillAwakeBecause I had a tooth pulled yesterday and took a long nap after So no sleep for me last night.', 749190822684291072)\n",
      "('IAmStillAwakeBecause You think I m not online But I m always here Even if I m not tweeting I m here Scrolling Judging Starin.', 749190815444901888)\n",
      "('IAmStillAwakeBecause Never Sleeps.', 749190807161372672)\n",
      "===========================================================\n",
      "#ChicagoInFourWords\n",
      "----------------------------------------------------------\n",
      "('Idiots keep electing liberals ChicagoInFourWords.', 749190911767248896)\n",
      "('City on a grid Neighborhoods are still segregated ChicagoInFourWords.', 749190881459265536)\n",
      "('ChicagoInFourWords I WANT TO VISIT.', 749190852191277056)\n",
      "('ChicagoInFourWords Democrats already banned Guns.', 749190820977270784)\n",
      "('I m not going there ChicagoInFourWords.', 749190789088043008)\n",
      "('ChicagoInFourWords Example of progressive government.', 749190760059265024)\n",
      "('Black thugs terrorize streets ChicagoInFourWords.', 749190755269406720)\n",
      "('Bang Bang Bang Bang ChicagoInFourWords.', 749190741021302784)\n",
      "('chicagoinfourwords Murder capital of America.', 749190722327371776)\n",
      "('Air brushed T shirts for ghetto funerals ChicagoInFourWords.', 749190707802415104)\n",
      "===========================================================\n"
     ]
    }
   ],
   "source": [
    "display(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "extract = get_top_tweets(tweets,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#growingupthick\n",
      "----------------------------------------------------------\n",
      "('growingupthick not being able to wear shorts cause it be so hot you get a rash between your thighs from rubbing together so.', 749190899264028672)\n",
      "('growingupthick when you sleep over a family members house amp no one can let you borrow jeans cause your considered fat.', 749190903546413056)\n",
      "('chaan growingupthick getting thigh rashes burns when wearing shorts dresses etc bc your thighs rub together ALL THE TIME.', 749190893056368640)\n",
      "===========================================================\n",
      "Joe Johnson\n",
      "----------------------------------------------------------\n",
      "('Joe Johnson is heading to the Jazz on a 2 year 22 million deal.', 749190926808059904)\n",
      "('According to our daldridgetnt Joe Johnson has agreed to a 2 year 22M deal with the Utah Jazz.', 749190686767886336)\n",
      "('Joe Johnson nuevo jugador de Utah Jazz firma por 2 aos y 22M.', 749190831802818560)\n",
      "===========================================================\n",
      "Germany vs Italy\n",
      "----------------------------------------------------------\n",
      "('Betfred betting specials for Euro 2016 continue tonight with Germany vs Italy Details.', 749190939948744705)\n",
      "('This tag can be defined as BBC defence vs German mid fielders Hoping Germany to make a win today Go Germany go Italy or Germany.', 749190980302041089)\n",
      "('EURO16onSonyLIV So to whom u are going to cheer in today s Italy Vs Germany Take part in Poll at SonyLIV.', 749190910479478784)\n",
      "===========================================================\n",
      "All 20\n",
      "----------------------------------------------------------\n",
      "('Age 7 I want to be a doctor Age 16 Mum look All A s Age 20 Medicine is hard Age 35 Make some noise for DJ Musa.', 749190945380372480)\n",
      "('20 I M A MORNING PERSON PPL I m not an anything person Y do u feel the need to wake people up to do morning ppl t.', 749190913335955456)\n",
      "('Breaking All 20 hostages killed during Bangladesh cafe siege were foreign army says.', 749190926715719680)\n",
      "===========================================================\n",
      "#ausvotes\n",
      "----------------------------------------------------------\n",
      "('Nothing splitting alexbhathal and Feeney4Batman in Batman with preferences playing a huge part in it ausvotes.', 749190933476880384)\n",
      "('Yes it is as we thought folks looks like LNP will again blame ALP if they lose the election ROFLMAO True to form auspol ausvotes.', 749190933195862016)\n",
      "('Does anyone know who Alan Jones bed wetter Lib friend on Channel 7 election coverage just now What a fight ausvotes auspol.', 749190932843552770)\n",
      "===========================================================\n",
      "#lastrelationshiptaughtme\n",
      "----------------------------------------------------------\n",
      "('LastRelationshipTaughtMe being faithful is just not enough.', 749190947078934528)\n",
      "('lastrelationshiptaughtme that loving someone too much will fuck you up.', 749190937532698625)\n",
      "('lastrelationshiptaughtme to walk away when you re no longer happy.', 749190917194518531)\n",
      "===========================================================\n",
      "Rihanna and Drake\n",
      "----------------------------------------------------------\n",
      "('Drake and Rihanna are officially dating.', 749191021406281728)\n",
      "('Rihanna and Drake are an official item and it is just TOO GOOD.', 749191005467971584)\n",
      "('Rihanna amp Drake OFFICIALLY together Read more here Rihanna Drake ANTIWorldTour.', 749191010727714816)\n",
      "===========================================================\n",
      "Melvindale\n",
      "----------------------------------------------------------\n",
      "('BREAKING Large gas line explosion in Melvindale homes evacuated Prayers up Details https.', 749190689930481664)\n",
      "('Photo of what appears to be the car that sparked the the gas line explosion in Melvindale https.', 749190974707003392)\n",
      "('PHOTO new daylight video of Melvindale explosion scene local4.', 749190515678208000)\n",
      "===========================================================\n",
      "#IAmStillAwakeBecause\n",
      "----------------------------------------------------------\n",
      "('IAmStillAwakeBecause ugh i cant sleep i can never sLEep.', 749190828078174209)\n",
      "('IAmStillAwakeBecause I don t sleep I just retreat to my racist cocoon which doubles as a tanning bed BAD.', 749190842762616832)\n",
      "('IAmStillAwakeBecause I couldn t sleep And the sad part is I gotta be to work in like three hours.', 749190891143778305)\n",
      "===========================================================\n",
      "#ChicagoInFourWords\n",
      "----------------------------------------------------------\n",
      "('I m not going there ChicagoInFourWords.', 749190789088043008)\n",
      "('ChicagoInFourWords Example of progressive government.', 749190760059265024)\n",
      "('ChicagoInFourWords I WANT TO VISIT.', 749190852191277056)\n",
      "===========================================================\n"
     ]
    }
   ],
   "source": [
    "display(extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final = get_top_tweets(extract,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#growingupthick\n",
      "----------------------------------------------------------\n",
      "('growingupthick not being able to wear shorts cause it be so hot you get a rash between your thighs from rubbing together so.', 749190899264028672)\n",
      "===========================================================\n",
      "Joe Johnson\n",
      "----------------------------------------------------------\n",
      "('According to our daldridgetnt Joe Johnson has agreed to a 2 year 22M deal with the Utah Jazz.', 749190686767886336)\n",
      "===========================================================\n",
      "Germany vs Italy\n",
      "----------------------------------------------------------\n",
      "('This tag can be defined as BBC defence vs German mid fielders Hoping Germany to make a win today Go Germany go Italy or Germany.', 749190980302041089)\n",
      "===========================================================\n",
      "All 20\n",
      "----------------------------------------------------------\n",
      "('20 I M A MORNING PERSON PPL I m not an anything person Y do u feel the need to wake people up to do morning ppl t.', 749190913335955456)\n",
      "===========================================================\n",
      "#ausvotes\n",
      "----------------------------------------------------------\n",
      "('Yes it is as we thought folks looks like LNP will again blame ALP if they lose the election ROFLMAO True to form auspol ausvotes.', 749190933195862016)\n",
      "===========================================================\n",
      "#lastrelationshiptaughtme\n",
      "----------------------------------------------------------\n",
      "('LastRelationshipTaughtMe being faithful is just not enough.', 749190947078934528)\n",
      "===========================================================\n",
      "Rihanna and Drake\n",
      "----------------------------------------------------------\n",
      "('Rihanna amp Drake OFFICIALLY together Read more here Rihanna Drake ANTIWorldTour.', 749191010727714816)\n",
      "===========================================================\n",
      "Melvindale\n",
      "----------------------------------------------------------\n",
      "('Photo of what appears to be the car that sparked the the gas line explosion in Melvindale https.', 749190974707003392)\n",
      "===========================================================\n",
      "#IAmStillAwakeBecause\n",
      "----------------------------------------------------------\n",
      "('IAmStillAwakeBecause ugh i cant sleep i can never sLEep.', 749190828078174209)\n",
      "===========================================================\n",
      "#ChicagoInFourWords\n",
      "----------------------------------------------------------\n",
      "('I m not going there ChicagoInFourWords.', 749190789088043008)\n",
      "===========================================================\n"
     ]
    }
   ],
   "source": [
    "display(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "''' Removing the main tweet from the summarised tweet\n",
    "    so as to facilitate the learning of the neural\n",
    "    network. Otherwise the network may learn to pick\n",
    "    up the main tweet as it is '''\n",
    "new_extract = extract.copy()\n",
    "for tag in extract:\n",
    "    new_extract[tag].remove(final[tag][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the data to filename: 07-02-2016.csv\n"
     ]
    }
   ],
   "source": [
    "save_csv(new_extract,final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to the pickel file named: 07-02-2016.csv\n"
     ]
    }
   ],
   "source": [
    "filename = strftime(\"%m-%d-%Y\")\n",
    "convert_pickel(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X,y = pickle.load(open(filename,\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H: growingupthick not being able to wear shorts cause it be so hot you get a rash between your thighs from rubbing together so.\n",
      "T: growingupthick when you sleep over a family members house amp no one can let you borrow jeans cause your considered fat.chaan growingupthick getting thigh rashes burns when wearing shorts dresses etc bc your thighs rub together ALL THE TIME.\n",
      "-----------------------------------------------------\n",
      "H: According to our daldridgetnt Joe Johnson has agreed to a 2 year 22M deal with the Utah Jazz.\n",
      "T: Joe Johnson is heading to the Jazz on a 2 year 22 million deal.Joe Johnson nuevo jugador de Utah Jazz firma por 2 aos y 22M.\n",
      "-----------------------------------------------------\n",
      "H: This tag can be defined as BBC defence vs German mid fielders Hoping Germany to make a win today Go Germany go Italy or Germany.\n",
      "T: Betfred betting specials for Euro 2016 continue tonight with Germany vs Italy Details.EURO16onSonyLIV So to whom u are going to cheer in today s Italy Vs Germany Take part in Poll at SonyLIV.\n",
      "-----------------------------------------------------\n",
      "H: 20 I M A MORNING PERSON PPL I m not an anything person Y do u feel the need to wake people up to do morning ppl t.\n",
      "T: Age 7 I want to be a doctor Age 16 Mum look All A s Age 20 Medicine is hard Age 35 Make some noise for DJ Musa.Breaking All 20 hostages killed during Bangladesh cafe siege were foreign army says.\n",
      "-----------------------------------------------------\n",
      "H: Yes it is as we thought folks looks like LNP will again blame ALP if they lose the election ROFLMAO True to form auspol ausvotes.\n",
      "T: Nothing splitting alexbhathal and Feeney4Batman in Batman with preferences playing a huge part in it ausvotes.Does anyone know who Alan Jones bed wetter Lib friend on Channel 7 election coverage just now What a fight ausvotes auspol.\n",
      "-----------------------------------------------------\n",
      "H: LastRelationshipTaughtMe being faithful is just not enough.\n",
      "T: lastrelationshiptaughtme that loving someone too much will fuck you up.lastrelationshiptaughtme to walk away when you re no longer happy.\n",
      "-----------------------------------------------------\n",
      "H: Rihanna amp Drake OFFICIALLY together Read more here Rihanna Drake ANTIWorldTour.\n",
      "T: Drake and Rihanna are officially dating.Rihanna and Drake are an official item and it is just TOO GOOD.\n",
      "-----------------------------------------------------\n",
      "H: Photo of what appears to be the car that sparked the the gas line explosion in Melvindale https.\n",
      "T: BREAKING Large gas line explosion in Melvindale homes evacuated Prayers up Details https.PHOTO new daylight video of Melvindale explosion scene local4.\n",
      "-----------------------------------------------------\n",
      "H: IAmStillAwakeBecause ugh i cant sleep i can never sLEep.\n",
      "T: IAmStillAwakeBecause I don t sleep I just retreat to my racist cocoon which doubles as a tanning bed BAD.IAmStillAwakeBecause I couldn t sleep And the sad part is I gotta be to work in like three hours.\n",
      "-----------------------------------------------------\n",
      "H: I m not going there ChicagoInFourWords.\n",
      "T: ChicagoInFourWords Example of progressive government.ChicagoInFourWords I WANT TO VISIT.\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X)):\n",
    "    print \"H: \"+str(X[i])\n",
    "    print \"T: \"+str(y[i])\n",
    "    print \"-----------------------------------------------------\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
